{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=0\n",
    "num_epochs = 1000\n",
    "input_layer_size = 2\n",
    "hidden_layer_1_size = 20\n",
    "hidden_layer_2_size = 10\n",
    "output_layer_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 3)\n",
      "(300, 3)\n",
      "(300, 3)\n"
     ]
    }
   ],
   "source": [
    "df_nls = pd.read_csv('Group20/Classification/NLS_Group20.txt', header=None, delimiter=\" \", skiprows=1)\n",
    "df_nls = df_nls.iloc[: , :-1]\n",
    "df_nls = df_nls.rename(columns={0: 'a', 1: 'b'})\n",
    "\n",
    "temp_df = [df_nls.iloc[:500,[0,1]], df_nls.iloc[500:1000,[0,1]], df_nls.iloc[1000:1500,[0,1]]]\n",
    "\n",
    "df_train_data = pd.DataFrame(columns = [\"a\", \"b\", \"class\"])\n",
    "df_valid_data = pd.DataFrame(columns = [\"a\", \"b\", \"class\"])\n",
    "df_test_data = pd.DataFrame(columns = [\"a\", \"b\", \"class\"])\n",
    "\n",
    "for i in range(3):\n",
    "    temp_df[i]['class'] = i+1\n",
    "    # split the dataset\n",
    "    validDataPercentage = 20\n",
    "    testDataPercentage = 20\n",
    "    training_data, testing_data = train_test_split(temp_df[i], test_size=(testDataPercentage+validDataPercentage)*0.01, random_state=random_state)\n",
    "    valid_data, testing_data = train_test_split(testing_data, test_size=(testDataPercentage/(testDataPercentage+validDataPercentage)), random_state=random_state)\n",
    "    df_train_data = pd.merge(df_train_data, training_data, how='outer')\n",
    "    df_valid_data = pd.merge(df_valid_data, valid_data, how='outer')\n",
    "    df_test_data  = pd.merge(df_test_data , testing_data, how='outer')\n",
    "\n",
    "\n",
    "df_train_data = df_train_data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "df_valid_data = df_valid_data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "df_test_data = df_test_data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "df_train_list = [df_train_data.loc[df_train_data['class'] == 1], df_train_data.loc[df_train_data['class'] == 2], df_train_data.loc[df_train_data['class'] == 3]]\n",
    "df_valid_list = [df_valid_data.loc[df_valid_data['class'] == 1], df_valid_data.loc[df_valid_data['class'] == 2], df_valid_data.loc[df_valid_data['class'] == 3]]\n",
    "df_test_list = [df_test_data.loc[df_test_data['class'] == 1], df_test_data.loc[df_test_data['class'] == 2], df_test_data.loc[df_test_data['class'] == 3]]\n",
    "\n",
    "\n",
    "print(df_train_data.shape)\n",
    "print(df_valid_data.shape)\n",
    "print(df_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot_encoder.fit_transform(df_train_data.iloc[:,-1].to_numpy().reshape(-1, 1))\n",
    "y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN:\n",
    "    def __init__(self, input_layer_size, hidden_layer_1_size, hidden_layer_2_size, output_layer_size):\n",
    "        # Input to hidden layer1 Matrix: (d+1) x j\n",
    "        np.random.seed(random_state)\n",
    "        self.wij = np.random.randn(input_layer_size, hidden_layer_1_size)\n",
    "        self.b1 = np.zeros((1, hidden_layer_1_size))\n",
    "        \n",
    "        # hidden layer1 to hidden layer2 Matrix: (j+1) x l\n",
    "        self.wjl = np.random.randn(hidden_layer_1_size, hidden_layer_2_size)\n",
    "        self.b2 = np.zeros((1, hidden_layer_2_size))\n",
    "        \n",
    "        # Output Matrix: (l+1) x k\n",
    "        self.learning_rate = 1\n",
    "        self.wlk = np.random.randn(hidden_layer_2_size, output_layer_size)\n",
    "        self.b3 = np.zeros((1, output_layer_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.a1 = np.dot(X, self.wij) + self.b1\n",
    "        # self.a1 = np.dot(X, self.wij)\n",
    "        self.h1 = self.g(self.a1)\n",
    "\n",
    "        self.a2 = np.dot(self.h1, self.wjl) + self.b2\n",
    "        # self.a2 = np.dot(self.h1, self.wjl)\n",
    "        self.h2 = self.g(self.a2)\n",
    "\n",
    "        self.a3 = np.dot(self.h2, self.wlk) + self.b3\n",
    "        # self.a3 = np.dot(self.h2, self.wlk)\n",
    "        self.h3 = self.f(self.a3)\n",
    "        \n",
    "        return self.h3\n",
    "    \n",
    "    def g(self, aj):\n",
    "        return np.tanh(aj)\n",
    "        # return 1/(1+np.exp(-aj))\n",
    "\n",
    "    def f(self, ak):\n",
    "        return 1/(1+np.exp(-ak))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def backward(self, X, y, y_pred):\n",
    "        m = X.shape[0]\n",
    "        dz3 = y_pred - y\n",
    "        dW3 = np.dot(self.h2.T, dz3) / m\n",
    "        db3 = np.sum(dz3, axis=0, keepdims=True) / m\n",
    "        dz2 = np.dot(dz3, self.wlk.T) * (1 - np.power(self.h2, 2))\n",
    "        dW2 = np.dot(self.h1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "        dz1 = np.dot(dz2, self.wjl.T) * (1 - np.power(self.h1, 2))\n",
    "        dW1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "        self.wlk -= self.learning_rate * dW3\n",
    "        self.b3 -= self.learning_rate * db3\n",
    "        self.wjl -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.wij -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X = X.iloc[:,:-1]\n",
    "        # X.insert(0,'hat',[1]*X.shape[0])\n",
    "        # print(X)\n",
    "        losses = []\n",
    "        for i in range(num_epochs):\n",
    "            self.learning_rate = 1/(i+1)\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.cross_entropy_loss(y_pred, y)\n",
    "            losses.append(loss)\n",
    "            self.backward(X, y_onehot, y_pred)\n",
    "            # if i % 100 == 0:\n",
    "                # print(f\"Epoch: {i}, Loss: {loss}\")\n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "\n",
    "    def cross_entropy_loss(self, y_pred, y_true):\n",
    "        m = y_true.shape[0]\n",
    "        log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)])\n",
    "        loss = np.sum(log_likelihood) / m\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "fcnn = FCNN(input_layer_size, hidden_layer_1_size, hidden_layer_2_size, output_layer_size)\n",
    "losses = fcnn.train(df_train_data, y_onehot)\n",
    "\n",
    "y_pred = np.argmax(fcnn.forward(df_test_data.iloc[:,:-1]), axis=1)\n",
    "y_pred = np.argmax(fcnn.forward(df_test_data.iloc[:,:-1]), axis=1) + 1\n",
    "accuracy = np.mean(y_pred == df_test_data.iloc[:,-1])\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hat  0  1\n",
      "0    1  1  4\n",
      "1    1  2  5\n",
      "2    1  3  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({0:[1, 2, 3],1:[4, 5, 6]})\n",
    "\n",
    "# insert a new column at the beginning\n",
    "df.insert(0,'hat',[1]*df.shape[0])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
